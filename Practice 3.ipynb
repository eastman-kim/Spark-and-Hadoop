{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice 2 - Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Instructions`\n",
    "- Get all customers who have placed order of amount more than 200.\n",
    "- Input files are tab delimeted files placed at below HDFS location:\n",
    "\t- /user/cloudera/practice2/problem3/customers\n",
    "\t- /user/cloudera/practice2/problem3/orders\n",
    "\t- /user/cloudera/practice2/problem3/order_items\n",
    "\n",
    "\n",
    "`Output Requirement`\n",
    "- Output should be placed in below HDFS Location /user/cloudera/practice2/problem3/joinResults\n",
    "- Output file should be comma seperated file with customer_fname,customer_lname,customer_city,order_amount.\n",
    "- Below header should be added to the output: fname, lname,city,price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data into HDFS\n",
    "sqoop import --connect \"jdbc:mysql://localhost/retail_db\" --password admin --username root --table orders --fields-terminated-by \"\\t\" --target-dir /user/cloudera/practice2/problem3/orders\n",
    "sqoop import --connect \"jdbc:mysql://localhost/retail_db\" --password admin --username root --table order_items --fields-terminated-by \"\\t\" --target-dir /user/cloudera/practice2/problem3/order_items\n",
    "sqoop import --connect \"jdbc:mysql://localhost/retail_db\" --password admin --username root --table customers --fields-terminated-by \"\\t\" --target-dir /user/cloudera/practice2/problem3/customers\n",
    "#load dataset\n",
    "orders = spark.read.option(\"sep\",\"\\t\").format(\"csv\").load(\"/user/cloudera/practice2/problem3/orders\")\n",
    "orderItems = spark.read.option(\"sep\",\"\\t\").format(\"csv\").load(\"/user/cloudera/practice2/problem3/order_items\")\n",
    "customers = spark.read.option(\"sep\",\"\\t\").format(\"csv\").load(\"/user/cloudera/practice2/problem3/customers\")\n",
    "#rename column names\n",
    "orders = orders.selectExpr(\"_c0 as order_id\", \"_c2 as customer_id\")\n",
    "orderItems = orderItems.selectExpr(\"_c1 as order_id\", \"_c4 as order_item_subtotal\")\n",
    "customers = customers.selectExpr(\"_c0 as customer_id\", \"_c1 as customer_fname\", \"_c2 as customer_lname\", \"_c6 as customer_city\")\n",
    "#run spark sql queries\n",
    "orderItems.createOrReplaceTempView(\"orderItems\")\n",
    "orderItemsFiltered = spark.sql(\"select order_id, sum(order_item_subtotal) as order_amount from orderItems group by order_id having sum(order_item_subtotal)>200\")\n",
    "#join dataframes\n",
    "o_oi_join = orders.join(orderItemsFiltered, \"order_id\")\n",
    "result = o_oi_join.join(customers, \"customer_id\")\n",
    "final = result.selectExpr(\"customer_fname as fname\", \"customer_lname as lname\", \"customer_city as city\", \"order_amount as price\")\n",
    "#save to HDFS\n",
    "final.write.option(\"sep\",\",\").format(\"csv\").save(\"/user/cloudera/practice2/problem3/joinResults\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice 2 - Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Instructions`\n",
    "- Get Customers from metastore table named \"customers_hive\" whose fname is like \"Rich\" and save the results in HDFS.\n",
    "\n",
    "\n",
    "`Output Requirement`\n",
    "- Result should be saved in /user/cloudera/practice2/problem4/customers/output.\n",
    "- Output should contain only fname, lname and city\n",
    "- Output should be saved in text format.\n",
    "- Output should be sorted by customer_city\n",
    "- fname and lname should seperated by tab with city seperated by colon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data into HDFS\n",
    "sqoop import --connect \"jdbc:mysql://localhost/retail_db\" --username root --password admin --table customers --warehouse-dir /user/cloudera/problem3/customers_hive/input --hive-import --create-hive-table --hive-database default --hive-table customers_hive\n",
    "#run spark sql queries\n",
    "res = spark.sql(\"select concat(customer_fname,\"\\t\",customer_lname,\":\",customer_city) from customers_hive where customer_fname like \"Rich%\" order by customer_city\")\n",
    "#save to HDFS\n",
    "res.write.format(\"text\").save(\"/user/cloudera/practice2/problem4/customers/output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice 2 - Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Instructions`\n",
    "- Provided pipe delimited file, get total numbers customers in each state whose first name starts with 'M'   and  save results in HDFS.\n",
    "- Input folder /user/cloudera/problem2/customer/tab\n",
    "\n",
    "`Output Requirement`\n",
    "- Result should be saved in a hive table \"customer_m\"\n",
    "- File format should be parquet file with gzip compression.\n",
    "- Output should have state name followed by total number of customers in that state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data into HDFS\n",
    "sqoop import --connect \"jdbc:mysql://localhost/retail_db\" --password admin --username root --table customers  --target-dir /user/cloudera/problem2/customer/tab --fields-terminated-by \"|\" --columns \"customer_id,customer_fname,customer_state\"\n",
    "#load dataset\n",
    "customers = spark.read.option(\"sep\",\"|\").format(\"csv\").load(\"/user/cloudera/problem2/customer/tab\")\n",
    "#rename columns\n",
    "customers = customers.selectExpr(\"_c0 as customer_id\", \"_c1 as customer_fname\", \"_c2 as customer_state\")\n",
    "#filter data\n",
    "customersFiltered = customers.filter(customers.customer_fname.like(\"M%\"))\n",
    "#run spark sql queries\n",
    "customersFiltered.createOrReplaceTempView(\"customers\")\n",
    "res = spark.sql(\"select customer_state, count(customer_fname) as count from customers group by customer_state\")\n",
    "#save to Hive\n",
    "res.write.mode(\"overwrite\").option(\"compression\",\"gzip\").option(\"fileFormat\",\"parquet\").format(\"hive\").saveAsTable(\"customer_m\") #returns error when column name includes any aggregating function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice 2 - Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Instructions`\n",
    "- Provided  a meta-store table named product_ranked consisting of product details ,find the most expensive product in each category.\n",
    "\n",
    "\n",
    "`Output Requirement`\n",
    "- Output should have product_category_id ,product_name,product_price,rank.\n",
    "- Result should be saved in /user/cloudera/pratice4/output/  as pipe delimited text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data into HDFS\n",
    "sqoop import --connect \"jdbc:mysql://localhost/retail_db\" --username root --password admin --table products --warehouse-dir /user/cloudera/practice4.db --hive-import --create-hive-table --hive-database default --hive-table product_ranked -m 1\n",
    "spark.sql(\"select * from product_ranked limit 10\").show()\n",
    "#run spark sql queries\n",
    "product_ranked_all = spark.sql(\"select product_category_id, product_name, product_price, RANK() over (partition by pr.product_category_id order by pr.product_price desc) as rank from product_ranked pr\")\n",
    "#convert into rdd and use map function to add pipeline delimiters\n",
    "product_ranked_first.rdd.map(lambda line: \"|\".join([str(x) for x in line])) \n",
    "#save to HDFS (cannot use write as it is not a DataFrame)\n",
    "product_ranked_first.saveAsTextFile(\"/user/cloudera/practice4/output\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice 2 - Question5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Instructions`\n",
    "- Fetch all pending orders from  data-files stored at hdfs location /user/cloudera/problem3/parquet and save it  into json file  in HDFS\n",
    "\n",
    "\n",
    "`Output Requirement`\n",
    "- Result should be saved in /user/cloudera/problem3/orders_pending\n",
    "- Output file should be saved as json file.\n",
    "- Output file should Gzip compressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data into HDFS\n",
    "sqoop import --connect \"jdbc:mysql://localhost/retail_db\" --password admin --username root --table orders --as-parquetfile --target-dir /user/cloudera/problem3/parquet\n",
    "#load as dataframe\n",
    "orders = spark.read.format(\"parquet\").load(\"/user/cloudera/problem3/parquet\")\n",
    "#filter pending orders\n",
    "ordersFiltered = orders.filter(orders.order_status == 'PENDING')\n",
    "#save to HDFS \n",
    "ordersFiltered.write.option(\"compression\",\"gzip\").format(\"json\").save(\"/user/cloudera/problem3/orders_pending\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice 2 - Question6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Instructions`\n",
    "- provided tab delimited file at hdfs location /user/cloudera/problem3/all/customer/input \n",
    "- save only first 4 field in the result as pipe delimited file in HDFS\n",
    "\n",
    "\n",
    "`Output Requirement`\n",
    "- Result should be saved in /user/cloudera/problem3/all/customer/output\n",
    "- Output file should be saved in text format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data into HDFS\n",
    "sqoop import --connect \"jdbc:mysql://localhost/retail_db\" --password admin --username root --table customers --fields-terminated-by '\\t'   --target-dir /user/cloudera/problem3/all/customer/input\n",
    "#load dataframe\n",
    "customers = spark.read.option(\"sep\",\"\\t\").format(\"csv\").load(\"/user/cloudera/problem3/all/customer/input\")\n",
    "#filter first four fields\n",
    "customersRenamed = customers.selectExpr(\"_c0 as customer_id\", \"_c1 as customer_fname\", \"_c2 as customer_lname\", \"_c3 as customer_email\")\n",
    "#convert into rdd and use map function to add pipeline delimiters\n",
    "customersRDD = customersRenamed.rdd.map(lambda line: \"|\".join([str(x) for x in line]))\n",
    "#save to HDFS (cannot use write as it is not a DataFrame)\n",
    "customersRDD.saveAsTextFile(\"/user/cloudera/problem3/all/customer/output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice 2 - Question7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Instructions`\n",
    "- Find top 10 products which has made highest revenue. \n",
    "- Products and order_items data are placed in HDFS directory /user/cloudera/practice4_ques6/order_items/ and /user/cloudera/practice4_ques6/products/  respectively. \n",
    "\n",
    "\n",
    "`Output Requirement`\n",
    "- Output should have product_id and revenue seperated with ':'  and should be saved in /user/cloudera/practice4_ques6/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data into HDFS\n",
    "sqoop import --connect \"jdbc:mysql://localhost/retail_db\" --username root --password admin --table order_items --target-dir /user/cloudera/practice4_ques6/order_items\n",
    "sqoop import --connect \"jdbc:mysql://localhost/retail_db\" --username root --password admin --table products --target-dir /user/cloudera/practice4_ques6/products/ -m 1\n",
    "#load dataframes\n",
    "orderItems = spark.read.format(\"csv\").load(\"/user/cloudera/practice4_ques6/order_items\")\n",
    "products = spark.read.format(\"csv\").load(\"/user/cloudera/practice4_ques6/products\")\n",
    "#rename columns\n",
    "orderItemsRenamed = orderItems.selectExpr(\"_c2 as product_id\", \"_c4 as order_item_subtotal\")\n",
    "productsRenamed = products.selectExpr(\"_c0 as product_id\")\n",
    "#join two dataframes\n",
    "join = productsRenamed.join(orderItemsRenamed, \"product_id\")\n",
    "#run sql queries\n",
    "join.createOrReplaceTempView(\"oi_p\")\n",
    "res = spark.sql(\"select product_id, sum(order_item_subtotal) as product_revenue from oi_p group by product_id order by product_revenue desc limit 10\")\n",
    "#add colon delmiters\n",
    "final = res.rdd.map(lambda line: \":\".join([str(x) for x in line]))\n",
    "#save to HDFS\n",
    "final.saveAsTextFile(\"/user/cloudera/practice4_ques6/output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice 2 - Question8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Instructions`\n",
    "- Find all customers that lives 'Brownsville' city and save the result into HDFS.\n",
    "- Input folder is  /user/cloudera/problem6/customer/text\n",
    "\n",
    "\n",
    "`Output Requirement`\n",
    "- Result should be saved in /user/cloudera/problem6/customer_Brownsville Output file should be saved in Json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data into HDFS\n",
    "sqoop import --connect \"jdbc:mysql://localhost/retail_db\" --password admin --username root --table customers --fields-terminated-by '\\t' --columns \"customer_id,customer_fname,customer_city\"  --target-dir /user/cloudera/problem6/customer/text\n",
    "#load dataframe\n",
    "customers = spark.read.option(\"sep\",\"\\t\").format(\"csv\").load(\"/user/cloudera/problem6/customer/text\")\n",
    "#rename columns\n",
    "customersRenamed = customers.selectExpr(\"_c0 as customer_id\", \"_c1 as customer_fname\",\"_c2 as customer_city\")\n",
    "#filter city where is Brownsville\n",
    "customersFiltered = customersRenamed.filter(customersRenamed.customer_city == \"Brownsville\")\n",
    "#save to HDFS\n",
    "customersFiltered.write.mode(\"overwrite\").format(\"json\").save(\"/user/cloudera/customer_Brownsville\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
